{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets, linear_model, preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_header = \"../results/do_not_delete/\"\n",
    "results_folders = []\n",
    "results_folders.append(results_header + \"2/\")\n",
    "results_folders.append(results_header + \"3/\")\n",
    "\n",
    "\n",
    "headers = []\n",
    "\n",
    "for results_folder in  results_folders:\n",
    "    for subfolder in os.listdir(results_folder):\n",
    "#         print(results_folder + subfolder)\n",
    "        for file in os.listdir(results_folder + subfolder):\n",
    "            if 'header' in file: \n",
    "                headers.append(results_folder + subfolder + \"/\" + file)\n",
    "                #print(results_folder + subfolder + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns=['ID','N','C','Depth','Lambda','Coll','Loss','Total_Loss','Trials'])\n",
    "\n",
    "for results_folder in results_folders:\n",
    "    for subfolder in os.listdir(results_folder):\n",
    "#         print(results_folder + subfolder)\n",
    "#         for file in os.listdir(results_folder + subfolder):\n",
    "#             if 'run_1_' in file:\n",
    "#                 print(\"ooo\")\n",
    "#                 start_str = file.split('_run_1_.')[0]\n",
    "        for file in os.listdir(results_folder + subfolder):\n",
    "            if ('header' in file):\n",
    "                headers.append(results_folder + subfolder + \"/\" + file)\n",
    "                openfile = results_folder + subfolder + \"/\" + file\n",
    "                run_type = 'M'\n",
    "                D = subfolder.split('d_')[1].split('_')[0]\n",
    "                C = subfolder.split('c_')[1].split('_')[0]\n",
    "                L = subfolder.split('l_')[1].split('_')[0]\n",
    "                N = subfolder.split('n_')[1].split('_')[0]\n",
    "                I = 500\n",
    "                ident = (N, I, D, run_type, L, C)\n",
    "#                 print(ident)\n",
    "                fheader = openfile[:-10]\n",
    "                try:\n",
    "                    df = pd.read_csv(fheader + \"data.csv\")\n",
    "                except: print(\"File not found: \" + fheader + \"data.csv\")\n",
    "                df['3'] = df['1'].diff()\n",
    "                df['4'] = df['2'].diff()\n",
    "                df['5'] = df.apply(lambda x: min(1, x['3'] + x['4']), axis=1)\n",
    "                if type == 'Q':\n",
    "                    if ident in Q:\n",
    "                        Q[ident] = Q[ident].append(df, ignore_index=True)\n",
    "                    else:\n",
    "                        Q[ident] = df\n",
    "                if run_type == 'M':\n",
    "                    if ident in M:\n",
    "                        M[ident] = M[ident].append(df, ignore_index=True)\n",
    "                    else:\n",
    "                        M[ident] = df\n",
    "                length = len(df)        \n",
    "                result = {'ID': ident, 'N': float(N), 'C': float(C), 'Depth': float(D), 'Lambda': float(L), \n",
    "                          'Loss': np.max(df['1']/length), 'Coll': np.max(df['2']/length), \n",
    "                          'Total_Loss': (np.sum(df['5'])-1)/length,'Trials': length}\n",
    "                if len(df_results[df_results['ID']==ident]) > 0:\n",
    "                    old_length = df_results.loc[df_results['ID']==ident, 'Trials']\n",
    "                    loss = df_results.loc[df_results['ID']==ident, 'Loss']\n",
    "                    coll = df_results.loc[df_results['ID']==ident, 'Coll']\n",
    "                    total = df_results.loc[df_results['ID']==ident, 'Total_Loss']\n",
    "                    loss = (loss*old_length + result['Loss']*length)/(old_length + length)\n",
    "                    coll = (coll*old_length + result['Coll']*length)/(old_length + length)\n",
    "                    total = (total*old_length + result['Total_Loss']*length)/(old_length + length)\n",
    "                    df_results.loc[df_results['ID']==ident, 'Trials'] += length\n",
    "                else:\n",
    "                    df_results = df_results.append(result, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>N</th>\n",
       "      <th>C</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Lambda</th>\n",
       "      <th>Coll</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Total_Loss</th>\n",
       "      <th>Trials</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(250, 500, 10, M, 0.85, 0.9)</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(500, 500, 10, M, 0.85, 0.9)</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(250, 500, 10, M, 0.85, 1.0)</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(500, 500, 10, M, 0.85, 1.0)</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(250, 500, 10, M, 0.85, 1.1)</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>(500, 500, 7, M, 0.95, 1.1)</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>(750, 500, 7, M, 0.95, 1.1)</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.01250</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01250</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>(1000, 500, 7, M, 0.9, 1.1)</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>0.01250</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>(500, 500, 7, M, 0.9, 1.1)</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>(750, 500, 7, M, 0.9, 1.1)</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ID       N    C  Depth  Lambda     Coll  \\\n",
       "0   (250, 500, 10, M, 0.85, 0.9)   250.0  0.9   10.0    0.85  0.02500   \n",
       "1   (500, 500, 10, M, 0.85, 0.9)   500.0  0.9   10.0    0.85  0.00625   \n",
       "2   (250, 500, 10, M, 0.85, 1.0)   250.0  1.0   10.0    0.85  0.02500   \n",
       "3   (500, 500, 10, M, 0.85, 1.0)   500.0  1.0   10.0    0.85  0.00000   \n",
       "4   (250, 500, 10, M, 0.85, 1.1)   250.0  1.1   10.0    0.85  0.05000   \n",
       "..                           ...     ...  ...    ...     ...      ...   \n",
       "67   (500, 500, 7, M, 0.95, 1.1)   500.0  1.1    7.0    0.95  0.00625   \n",
       "68   (750, 500, 7, M, 0.95, 1.1)   750.0  1.1    7.0    0.95  0.01250   \n",
       "69   (1000, 500, 7, M, 0.9, 1.1)  1000.0  1.1    7.0    0.90  0.00625   \n",
       "70    (500, 500, 7, M, 0.9, 1.1)   500.0  1.1    7.0    0.90  0.03125   \n",
       "71    (750, 500, 7, M, 0.9, 1.1)   750.0  1.1    7.0    0.90  0.00000   \n",
       "\n",
       "       Loss  Total_Loss Trials  \n",
       "0   0.00625     0.02500   1280  \n",
       "1   0.00000     0.00625   1280  \n",
       "2   0.00000     0.02500   1280  \n",
       "3   0.00000     0.00000   1280  \n",
       "4   0.00000     0.05000   1280  \n",
       "..      ...         ...    ...  \n",
       "67  0.00000     0.00625   1280  \n",
       "68  0.00000     0.01250   1280  \n",
       "69  0.00625     0.01250   1280  \n",
       "70  0.00000     0.03125   1280  \n",
       "71  0.00000     0.00000   1280  \n",
       "\n",
       "[72 rows x 9 columns]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>C</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Lambda</th>\n",
       "      <th>Coll</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Total_Loss</th>\n",
       "      <th>Trials</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           N    C  Depth  Lambda   Coll  Loss  Total_Loss    Trials\n",
       "0   0.000000  0.0    1.0     0.0  0.500   0.5    0.444444  0.111111\n",
       "1   0.333333  0.0    1.0     0.0  0.125   0.0    0.111111  0.111111\n",
       "2   0.000000  0.5    1.0     0.0  0.500   0.0    0.444444  0.111111\n",
       "3   0.333333  0.5    1.0     0.0  0.000   0.0    0.000000  0.111111\n",
       "4   0.000000  1.0    1.0     0.0  1.000   0.0    0.888889  0.111111\n",
       "..       ...  ...    ...     ...    ...   ...         ...       ...\n",
       "67  0.333333  1.0    0.4     1.0  0.125   0.0    0.111111  0.111111\n",
       "68  0.666667  1.0    0.4     1.0  0.250   0.0    0.222222  0.111111\n",
       "69  1.000000  1.0    0.4     0.5  0.125   0.5    0.222222  0.111111\n",
       "70  0.333333  1.0    0.4     0.5  0.625   0.0    0.555556  0.111111\n",
       "71  0.666667  1.0    0.4     0.5  0.000   0.0    0.000000  0.111111\n",
       "\n",
       "[72 rows x 8 columns]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_results.values \n",
    "x = [xx[1:] for xx in x]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_scaled = pd.DataFrame(x_scaled, columns=['N','C','Depth','Lambda','Coll','Loss','Total_Loss','Trials'])\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Total_Loss</td>    <th>  R-squared:         </th> <td>   0.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.332</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9.834</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 01 Oct 2021</td> <th>  Prob (F-statistic):</th> <td>2.55e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:22:26</td>     <th>  Log-Likelihood:    </th> <td>  17.858</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    72</td>      <th>  AIC:               </th> <td>  -25.72</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    67</td>      <th>  BIC:               </th> <td>  -14.33</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.3662</td> <td>    0.057</td> <td>    6.382</td> <td> 0.000</td> <td>    0.252</td> <td>    0.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>N</th>         <td>   -0.4799</td> <td>    0.078</td> <td>   -6.185</td> <td> 0.000</td> <td>   -0.635</td> <td>   -0.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C</th>         <td>    0.1206</td> <td>    0.062</td> <td>    1.934</td> <td> 0.057</td> <td>   -0.004</td> <td>    0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Depth</th>     <td>    0.0164</td> <td>    0.056</td> <td>    0.293</td> <td> 0.770</td> <td>   -0.096</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lambda</th>    <td>    0.0139</td> <td>    0.057</td> <td>    0.246</td> <td> 0.807</td> <td>   -0.099</td> <td>    0.127</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.623</td> <th>  Durbin-Watson:     </th> <td>   1.969</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.099</td> <th>  Jarque-Bera (JB):  </th> <td>   4.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.607</td> <th>  Prob(JB):          </th> <td>   0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.864</td> <th>  Cond. No.          </th> <td>    5.38</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Total_Loss   R-squared:                       0.370\n",
       "Model:                            OLS   Adj. R-squared:                  0.332\n",
       "Method:                 Least Squares   F-statistic:                     9.834\n",
       "Date:                Fri, 01 Oct 2021   Prob (F-statistic):           2.55e-06\n",
       "Time:                        07:22:26   Log-Likelihood:                 17.858\n",
       "No. Observations:                  72   AIC:                            -25.72\n",
       "Df Residuals:                      67   BIC:                            -14.33\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.3662      0.057      6.382      0.000       0.252       0.481\n",
       "N             -0.4799      0.078     -6.185      0.000      -0.635      -0.325\n",
       "C              0.1206      0.062      1.934      0.057      -0.004       0.245\n",
       "Depth          0.0164      0.056      0.293      0.770      -0.096       0.128\n",
       "Lambda         0.0139      0.057      0.246      0.807      -0.099       0.127\n",
       "==============================================================================\n",
       "Omnibus:                        4.623   Durbin-Watson:                   1.969\n",
       "Prob(Omnibus):                  0.099   Jarque-Bera (JB):                4.480\n",
       "Skew:                           0.607   Prob(JB):                        0.106\n",
       "Kurtosis:                       2.864   Cond. No.                         5.38\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = smf.ols('Total_Loss ~ N + C + Depth + Lambda', data=df_scaled).fit()\n",
    "reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in Q:\n",
    "#     print(q, end=\": \")\n",
    "#     print(len(Q[q]['3']), end=\": \")\n",
    "#     print(np.mean(Q[q]['1']),end = \", \")\n",
    "#     print(np.mean(Q[q]['2']),end = \", \")\n",
    "# #     print(np.mean(Q[q]['3']))\n",
    "\n",
    "# depth_series = [[],[]]\n",
    "# c_series = [[],[]]\n",
    "# lambda_series = [[],[]]\n",
    "\n",
    "# n_array = [250, 500, 750, 1000]\n",
    "# depth_array = [5, 7, 10]\n",
    "# gamma_array = [.85, .9, .95]\n",
    "\n",
    "# for m in M:\n",
    "#     print(m, end=\": \")\n",
    "#     print(len(M[m]['3']), end=\": \")\n",
    "#     print(np.mean(M[m]['1']),end = \", \")\n",
    "#     print(np.mean(M[m]['2']),end = \", \")\n",
    "#     print(np.mean(M[m]['3']),end = \", \")\n",
    "#     print(np.var(M[m]['3']))\n",
    "#     if m[5] == 1.0 and m[4] == 0.9:\n",
    "#         depth_series[0].append(m[2])\n",
    "#         depth_series[1].append(np.mean(M[m]['3']))\n",
    "#     if m[2] == 5 and m[4] == 0.9:\n",
    "#         c_series[0].append(m[5])\n",
    "#         c_series[1].append(np.mean(M[m]['3']))\n",
    "#     if m[5] == 10:\n",
    "#         lambda_series[0].append(m[4])\n",
    "#         lambda_series[1].append(np.mean(M[m]['3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array(depth_series).T, columns=(\"depth\",\"loss\"))\n",
    "sns.scatterplot(data = df, x=\"depth\", y=\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.array(c_series).T, columns=(\"c\",\"loss\"))\n",
    "sns.scatterplot(data = df, x=\"c\", y=\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array(lambda_series).T, columns=(\"lambda\",\"loss\"))\n",
    "sns.scatterplot(data = df, x=\"lambda\", y=\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import ggplot, geom_point, aes, stat_smooth, facet_wrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (197004923992)>"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ggplot(df_results, aes('C', 'Total Loss'))\n",
    "+ geom_point()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q = {}\n",
    "# M = {}\n",
    "# for fname in headers:\n",
    "#     openfile = fname\n",
    "#     print(fname)\n",
    "#     f = open(openfile, \"r\")\n",
    "#     N=0\n",
    "#     I=0\n",
    "#     D=0\n",
    "#     c = False\n",
    "#     Lambda = False\n",
    "#     run_type = ''\n",
    "#     reading = True\n",
    "    \n",
    "#     while(reading):\n",
    "#         line = f.readline()\n",
    "        \n",
    "#         if not line:\n",
    "#             reading = False\n",
    "#         if 'Q' in line.strip():\n",
    "#             run_type = 'Q'\n",
    "#         if 'M' in line.strip():\n",
    "#             run_type = 'M'\n",
    "#         if 'N' in line.strip():\n",
    "#             try: N = int(line.strip()[-4:])\n",
    "#             except: N = int(line.strip()[-2:])\n",
    "#         if 'Iterations' in line.strip():\n",
    "#             try: I = int(line.strip()[-4:])\n",
    "#             except: \n",
    "#                 I = int(line.strip()[-2:])\n",
    "#         if 'Depth' in line.strip():\n",
    "#             try: D = int(line.strip()[-3:])    \n",
    "#             except: \n",
    "#                 try: D = int(line.strip()[-1:])    \n",
    "#                 except: D = False\n",
    "#         if 'Lambda:' in line.strip():\n",
    "            \n",
    "#             try: \n",
    "#                 Lambda = float(line.strip()[7:])\n",
    "#             except: \n",
    "#                 Lambda = False\n",
    "#         if 'c:' in line.strip():\n",
    "#             try: c = float(line.strip()[3:])\n",
    "#             except: c = False\n",
    "#         ident = (N, I, D, run_type, Lambda, c)\n",
    "#         fheader = fname[:-10]\n",
    "#     try:\n",
    "#         df = pd.read_csv(fheader + \"data.csv\")\n",
    "#         df['3'] = df.apply(lambda x: min(1, x['1'] + x['2']), axis=1)\n",
    "#         if type == 'Q':\n",
    "#             if ident in Q:\n",
    "#                 Q[ident] = Q[ident].append(df, ignore_index=True)\n",
    "#             else:\n",
    "#                 Q[ident] = df\n",
    "#         if run_type == 'M':\n",
    "#             if ident in M:\n",
    "#                 M[ident] = M[ident].append(df, ignore_index=True)\n",
    "#             else:\n",
    "#                 M[ident] = df\n",
    "#     except: print(\"File not found: \" + fheader + \"data.csv\")\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
